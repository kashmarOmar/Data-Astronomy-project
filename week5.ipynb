{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f24dbf33",
   "metadata": {},
   "source": [
    "# 5a – Week 5: Building a regression classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a390b639",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write a get_features_targets function that splits the training data into input features and their corresponding targets. In our case, the inputs are the 4 colour indices and our targets are the corresponding redshifts. \n",
    "import numpy as np\n",
    "def get_features_targets(data):\n",
    "  features = np.zeros(shape=(len(data), 4))\n",
    "  features[:, 0] = data['u'] - data['g']\n",
    "  features[:, 1] = data['g'] - data['r']\n",
    "  features[:, 2] = data['r'] - data['i']\n",
    "  features[:, 3] = data['i'] - data['z']\n",
    "  targets = data['redshift']\n",
    "  return features, targets\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  # load the data\n",
    "  data = np.load('sdss_galaxy_colors.npy')\n",
    "    \n",
    "  # call our function \n",
    "  features, targets = get_features_targets(data)\n",
    "    \n",
    "  # print the shape of the returned arrays\n",
    "  print(features[:2])\n",
    "  print(targets[:2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9135388",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# copy in your get_features_targets function here\n",
    "def get_features_targets(data):\n",
    "  features = np.zeros(shape=(len(data), 4))\n",
    "  features[:, 0] = data['u'] - data['g']\n",
    "  features[:, 1] = data['g'] - data['r']\n",
    "  features[:, 2] = data['r'] - data['i']\n",
    "  features[:, 3] = data['i'] - data['z']\n",
    "  targets = data['redshift']\n",
    "  return features, targets\n",
    "\n",
    "# load the data and generate the features and targets\n",
    "data = np.load('sdss_galaxy_colors.npy')\n",
    "features, targets = get_features_targets(data)\n",
    "  \n",
    "# initialize model\n",
    "dtr = DecisionTreeRegressor()\n",
    "\n",
    "# train the model\n",
    "dtr.fit(features, targets)\n",
    "\n",
    "# make predictions using the same features\n",
    "predictions = dtr.predict(features)\n",
    "\n",
    "# print out the first 4 predicted redshifts\n",
    "print(predictions[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3184cd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The median_diff function takes two arguments – the predicted and actual/target values. When we use this function later in the tutorial, these will corresponding to the predicted redshifts from our decision tree and their corresponding measured/target values.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# write a function that calculates the median of the differences\n",
    "# between our predicted and actual values\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Write a function that calculates the median of the differences between our predicted and actual values\n",
    "def median_diff(predicted, actual):\n",
    "  return np.median(np.abs(predicted[:] - actual[:]))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  # load testing data\n",
    "  targets = np.load('targets.npy')\n",
    "  predictions = np.load('predictions.npy')\n",
    "\n",
    "  # call your function to measure the accuracy of the predictions\n",
    "  diff = median_diff(predictions, targets)\n",
    "\n",
    "  # print the median difference\n",
    "  print(\"Median difference: {:0.3f}\".format(diff))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013073fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# paste your get_features_targets function here\n",
    "def get_features_targets(data):\n",
    "  features = np.zeros((data.shape[0], 4))\n",
    "  features[:, 0] = data['u'] - data['g']\n",
    "  features[:, 1] = data['g'] - data['r']\n",
    "  features[:, 2] = data['r'] - data['i']\n",
    "  features[:, 3] = data['i'] - data['z']\n",
    "  targets = data['redshift']\n",
    "  return features, targets\n",
    "\n",
    "# paste your median_diff function here\n",
    "def median_diff(predicted, actual):\n",
    "  return np.median(np.abs(predicted - actual))\n",
    "\n",
    "# write a function that splits the data into training and testing subsets\n",
    "# trains the model and returns the prediction accuracy with median_diff\n",
    "def validate_model(model, features, targets):\n",
    "  # split the data into training and testing\n",
    "  split = 2*features.shape[0]//3\n",
    "  train_features, test_features = features[:split], features[split:]\n",
    "  train_targets, test_targets = targets[:split], targets[split:]\n",
    "\n",
    "  # train the model\n",
    "  model.fit(train_features, train_targets)\n",
    "\n",
    "  # get the predicted_redshifts\n",
    "  predictions = model.predict(test_features)  \n",
    "  \n",
    "  # use median_diff function to calculate the accuracy\n",
    "  return median_diff(test_targets, predictions)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  data = np.load('sdss_galaxy_colors.npy')\n",
    "  features, targets = get_features_targets(data)\n",
    "\n",
    "  # initialize model\n",
    "  dtr = DecisionTreeRegressor()\n",
    "\n",
    "  # validate the model and print the med_diff\n",
    "  diff = validate_model(dtr, features, targets)\n",
    "  print('Median difference: {:f}'.format(diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc85e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your task here is simply to try and re-create the following plot. \n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Complete the following to make the plot\n",
    "if __name__ == \"__main__\":\n",
    "    data = np.load('sdss_galaxy_colors_limz.npy')\n",
    "    # Get a colour map\n",
    "    cmap = plt.get_cmap('YlOrRd')\n",
    "\n",
    "    # Define our colour indexes u-g and r-i\n",
    "    u_g = data['u'] - data['g']\n",
    "    r_i = data['r'] - data['i']\n",
    "\n",
    "    # Make a redshift array\n",
    "    redshift = data['redshift']\n",
    "\n",
    "    # Create the plot with plt.scatter\n",
    "    plot = plt.scatter(u_g, r_i, s=0.5, lw=0, c=redshift, cmap=cmap)\n",
    "\n",
    "    cb = plt.colorbar(plot)\n",
    "    cb.set_label('Redshift')\n",
    "\n",
    "    # Define your axis labels and plot title\n",
    "    plt.xlabel('Colour index  u-g')\n",
    "    plt.ylabel('Colour index  r-i')\n",
    "    plt.title('Redshift (colour) u-g versus r-i')\n",
    "\n",
    "    # Set any axis limits\n",
    "    plt.xlim(-0.5, 2.5)\n",
    "    plt.ylim(-0.5, 1)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8803b0fb",
   "metadata": {},
   "source": [
    "## 5b – Week 5: Improving and evaluating our classifier \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799670e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete the function accuracy_by_treedepth. The function should return the median difference for both the testing and training data sets for each of the tree depths in depths. \n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# paste your get_features_targets function here\n",
    "def get_features_targets(data):\n",
    "  features = np.zeros((data.shape[0], 4))\n",
    "  features[:, 0] = data['u'] - data['g']\n",
    "  features[:, 1] = data['g'] - data['r']\n",
    "  features[:, 2] = data['r'] - data['i']\n",
    "  features[:, 3] = data['i'] - data['z']\n",
    "  targets = data['redshift']\n",
    "  return features, targets\n",
    "\n",
    "# paste your median_diff function here\n",
    "def median_diff(predicted, actual):\n",
    "  return np.median(np.abs(predicted - actual))\n",
    "\n",
    "# Complete the following function\n",
    "def accuracy_by_treedepth(features, targets, depths):\n",
    "  # split the data into testing and training sets\n",
    "  split = features.shape[0]//2\n",
    "  train_features, test_features = features[:split], features[split:]\n",
    "  train_targets, test_targets = targets[:split], targets[split:]\n",
    "\n",
    "  # Initialise arrays or lists to store the accuracies for the below loop\n",
    "  train_diffs = []\n",
    "  test_diffs = []\n",
    "\n",
    "  # Loop through depths\n",
    "  for depth in depths:\n",
    "    # initialize model with the maximum depth. \n",
    "    dtr = DecisionTreeRegressor(max_depth=depth)\n",
    "\n",
    "    # train the model using the training set\n",
    "    dtr.fit(train_features, train_targets)\n",
    "\n",
    "    # Get the predictions for the training set and calculate their med_diff\n",
    "    predictions = dtr.predict(train_features)\n",
    "    train_diffs.append(median_diff(train_targets, predictions))\n",
    "\n",
    "    # Get the predictions for the testing set and calculate their med_diff\n",
    "    predictions = dtr.predict(test_features)\n",
    "    test_diffs.append(median_diff(test_targets, predictions))\n",
    "        \n",
    "  # Return the accuracies for the training and testing sets\n",
    "  return train_diffs, test_diffs    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  data = np.load('sdss_galaxy_colors.npy')\n",
    "  features, targets = get_features_targets(data)\n",
    "\n",
    "  # Generate several depths to test\n",
    "  tree_depths = [i for i in range(1, 36, 2)]\n",
    "\n",
    "  # Call the function\n",
    "  train_med_diffs, test_med_diffs = accuracy_by_treedepth(features, targets, tree_depths)\n",
    "  print(\"Depth with lowest median difference : {}\".format(tree_depths[test_med_diffs.index(min(test_med_diffs))]))\n",
    "    \n",
    "  # Plot the results\n",
    "  train_plot = plt.plot(tree_depths, train_med_diffs, label='Training set')\n",
    "  test_plot = plt.plot(tree_depths, test_med_diffs, label='Validation set')\n",
    "  plt.xlabel(\"Maximum Tree Depth\")\n",
    "  plt.ylabel(\"Median of Differences\")\n",
    "  plt.legend()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a951f40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your task is to complete the function cross_validate_model. The function takes 4 arguments: \n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# paste your get_features_targets function here\n",
    "def get_features_targets(data):\n",
    "  features = np.zeros((data.shape[0], 4))\n",
    "  features[:, 0] = data['u'] - data['g']\n",
    "  features[:, 1] = data['g'] - data['r']\n",
    "  features[:, 2] = data['r'] - data['i']\n",
    "  features[:, 3] = data['i'] - data['z']\n",
    "  targets = data['redshift']\n",
    "  return features, targets\n",
    "\n",
    "# paste your median_diff function here\n",
    "def median_diff(predicted, actual):\n",
    "  return np.median(np.abs(predicted - actual))\n",
    "\n",
    "# complete this function\n",
    "def cross_validate_model(model, features, targets, k):\n",
    "  kf = KFold(n_splits=k, shuffle=True)\n",
    "\n",
    "  # initialise a list to collect median_diffs for each iteration of the loop below\n",
    "  diffs = []\n",
    "\n",
    "  for train_indices, test_indices in kf.split(features):\n",
    "    train_features, test_features = features[train_indices], features[test_indices]\n",
    "    train_targets, test_targets = targets[train_indices], targets[test_indices]\n",
    "    \n",
    "    # fit the model for the current set\n",
    "    model.fit(train_features, train_targets)\n",
    "    \n",
    "    # predict using the model\n",
    "    predictions = model.predict(test_features)\n",
    " \n",
    "    # calculate the median_diff from predicted values and append to results array\n",
    "    diffs.append(median_diff(predictions, test_targets))\n",
    " \n",
    "  # return the list with your median difference values\n",
    "  return diffs\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  data = np.load('./sdss_galaxy_colors.npy')\n",
    "  features, targets = get_features_targets(data)\n",
    "\n",
    "  # initialize model with a maximum depth of 19\n",
    "  dtr = DecisionTreeRegressor(max_depth=19)\n",
    "\n",
    "  # call your cross validation function\n",
    "  diffs = cross_validate_model(dtr, features, targets, 10)\n",
    "\n",
    "  # Print the values\n",
    "  print('Differences: {}'.format(', '.join(['{:.3f}'.format(val) for val in diffs])))\n",
    "  print('Mean difference: {:.3f}'.format(np.mean(diffs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c008446",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# paste your get_features_targets function here\n",
    "def get_features_targets(data):\n",
    "  features = np.zeros((data.shape[0], 4))\n",
    "  features[:, 0] = data['u'] - data['g']\n",
    "  features[:, 1] = data['g'] - data['r']\n",
    "  features[:, 2] = data['r'] - data['i']\n",
    "  features[:, 3] = data['i'] - data['z']\n",
    "  targets = data['redshift']\n",
    "  return features, targets\n",
    "\n",
    "# paste your median_diff function here\n",
    "def median_diff(predicted, actual):\n",
    "  return np.median(np.abs(predicted - actual))\n",
    "\n",
    "# complete this function\n",
    "def cross_validate_predictions(model, features, targets, k):\n",
    "  kf = KFold(n_splits=k, shuffle=True)\n",
    "\n",
    "  all_predictions = np.zeros_like(targets)\n",
    "\n",
    "  for train_indices, test_indices in kf.split(features):\n",
    "    # split the data into training and testing\n",
    "    train_features, test_features = features[train_indices], features[test_indices]\n",
    "    train_targets, test_targets = targets[train_indices], targets[test_indices]\n",
    "    \n",
    "    # fit the model for the current set\n",
    "    model.fit(train_features, train_targets)\n",
    "        \n",
    "    # predict using the model\n",
    "    predictions = model.predict(test_features)\n",
    "        \n",
    "    # put the predicted values in the all_predictions array defined above\n",
    "    all_predictions[test_indices] = predictions\n",
    "\n",
    "  # return the predictions\n",
    "  return all_predictions\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  data = np.load('./sdss_galaxy_colors.npy')\n",
    "  features, targets = get_features_targets(data)\n",
    "\n",
    "  # initialize model\n",
    "  dtr = DecisionTreeRegressor(max_depth=19)\n",
    "\n",
    "  # call your cross validation function\n",
    "  predictions = cross_validate_predictions(dtr, features, targets, 10)\n",
    "\n",
    "  # calculate and print the rmsd as a sanity check\n",
    "  diffs = median_diff(predictions, targets)\n",
    "  print('Median difference: {:.3f}'.format(diffs))\n",
    "\n",
    "  # plot the results to see how well our model looks\n",
    "  plt.scatter(targets, predictions, s=0.4)\n",
    "  plt.xlim((0, targets.max()))\n",
    "  plt.ylim((0, predictions.max()))\n",
    "  plt.xlabel('Measured Redshift')\n",
    "  plt.ylabel('Predicted Redshift')\n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1a1af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function split_galaxies_qsos that splits our data containing both galaxies and QSOs into two arrays that contain only galaxies and QSOs respectively. Your function should take a single data argument. \n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# paste your get_features_targets function here\n",
    "def get_features_targets(data):\n",
    "  features = np.zeros((data.shape[0], 4))\n",
    "  features[:, 0] = data['u'] - data['g']\n",
    "  features[:, 1] = data['g'] - data['r']\n",
    "  features[:, 2] = data['r'] - data['i']\n",
    "  features[:, 3] = data['i'] - data['z']\n",
    "  targets = data['redshift']\n",
    "  return features, targets\n",
    "\n",
    "# paste your median_diff function here\n",
    "def median_diff(predicted, actual):\n",
    "  return np.median(np.abs(predicted - actual))\n",
    "\n",
    "# paste your cross_validate_model function here\n",
    "def cross_validate_model(model, features, targets, k):\n",
    "  kf = KFold(n_splits=k, shuffle=True)\n",
    "\n",
    "  # initialise a list to collect median_diffs for each iteration of the loop below\n",
    "  diffs = []\n",
    "\n",
    "  for train_indices, test_indices in kf.split(features):\n",
    "    train_features, test_features = features[train_indices], features[test_indices]\n",
    "    train_targets, test_targets = targets[train_indices], targets[test_indices]\n",
    "    \n",
    "    # fit the model for the current set\n",
    "    model.fit(train_features, train_targets)\n",
    "    \n",
    "    # predict using the model\n",
    "    predictions = model.predict(test_features)\n",
    " \n",
    "    # calculate the median_diff from predicted values and append to results array\n",
    "    diffs.append(median_diff(predictions, test_targets))\n",
    " \n",
    "  # return the list with your median difference values\n",
    "  return diffs\n",
    "\n",
    "# complete this function\n",
    "def split_galaxies_qsos(data):\n",
    "  # split the data into galaxies and qsos arrays\n",
    "  galaxies = data[data['spec_class'] == b'GALAXY']\n",
    "  qsos = data[data['spec_class'] == b'QSO']\n",
    "\n",
    "  # return the seperated galaxies and qsos arrays\n",
    "  return galaxies, qsos\n",
    "\n",
    "def cross_validate_median_diff(data):\n",
    "  features, targets = get_features_targets(data)\n",
    "  dtr = DecisionTreeRegressor(max_depth=19)\n",
    "  return np.mean(cross_validate_model(dtr, features, targets, 10))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  data = np.load('./sdss_galaxy_colors.npy')\n",
    "\n",
    "  # split the data set into galaxies and QSOs\n",
    "  galaxies, qsos= split_galaxies_qsos(data)\n",
    "\n",
    "  # here we cross validate the model and get the cross-validated median difference\n",
    "  # the cross_validated_med_diff function is in \"written_functions\"\n",
    "  galaxy_med_diff = cross_validate_median_diff(galaxies)\n",
    "  qso_med_diff = cross_validate_median_diff(qsos)\n",
    "\n",
    "  # print the results\n",
    "  print(\"Median difference for Galaxies: {:.3f}\".format(galaxy_med_diff))\n",
    "  print(\"Median difference for QSOs: {:.3f}\".format(qso_med_diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb992e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
